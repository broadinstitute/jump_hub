{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbc7f39-93fa-4dbf-ba7b-a877dcc1d0da",
   "metadata": {},
   "source": [
    "# Retrieve JUMP profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ad0d1ccd778a-b7ab-fbd4-af39-93f7cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jump_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18eed2a3",
   "metadata": {
    "title": "Imports"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5ec75-e400-4d6f-ac58-095282a6a008",
   "metadata": {},
   "source": [
    "The JUMP Cell Painting project provides several processed datasets for\n",
    "morphological profiling. Choose the dataset that matches your\n",
    "perturbation type:\n",
    "\n",
    "-   **`crispr`**: CRISPR knockout genetic perturbations\n",
    "-   **`orf`**: Open Reading Frame (ORF) overexpression perturbations\n",
    "-   **`compound`**: Chemical compound perturbations\n",
    "-   **`all`**: Combined dataset containing all perturbation types (use\n",
    "    for cross-modality comparisons)\n",
    "\n",
    "Each dataset is available in two processing versions:\n",
    "\n",
    "-   **Standard** (e.g., `crispr`, `compound`, `orf`): Fully processed\n",
    "    including batch correction steps. **Recommended for most analyses**\n",
    "    as they provide better cross-dataset comparability.\n",
    "\n",
    "-   **Interpretable** (e.g., `crispr_interpretable`,\n",
    "    `compound_interpretable`, `orf_interpretable`): Same initial\n",
    "    processing but without batch correction transformations that modify\n",
    "    the original feature space. Use these when you need to interpret\n",
    "    individual morphological features.\n",
    "\n",
    "All datasets are stored as Parquet files on AWS S3 and can be accessed\n",
    "directly via their URLs.\n",
    "\n",
    "The index file below contains the **recommended profiles** for each\n",
    "subset. Each profile includes: - Direct links to the processing recipe\n",
    "and configuration used - ETags for data integrity verification\n",
    "\n",
    "For details on creating your own profile manifests, see the [manifest\n",
    "guide](https://github.com/broadinstitute/jump_hub/blob/main/howto/2_create_project_manifest.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab0d72e",
   "metadata": {
    "title": "Paths"
   },
   "outputs": [],
   "source": [
    "INDEX_FILE = \"https://raw.githubusercontent.com/jump-cellpainting/datasets/v0.11.0/manifests/profile_index.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac6636-6637-4acf-8580-c7cbb870a273",
   "metadata": {},
   "source": [
    "We use the version-controlled manifest above to release the latest\n",
    "corrected profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c62263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- orf: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/ORF/v1.0a/profiles_wellpos_cc_var_mad_outlier_featselect_sphering_harmony.parquet\n",
      "- crispr: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/CRISPR/v1.0a/profiles_wellpos_cc_var_mad_outlier_featselect_sphering_harmony_PCA_corrected.parquet\n",
      "- compound: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/COMPOUND/v1.0/profiles_var_mad_int_featselect_harmony.parquet\n",
      "- orf_interpretable: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/ORF/v1.0a/profiles_wellpos_cc_var_mad_outlier.parquet\n",
      "- crispr_interpretable: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/CRISPR/v1.0a/profiles_wellpos_cc_var_mad_outlier.parquet\n",
      "- compound_interpretable: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/COMPOUND/v1.0/profiles_var_mad_int.parquet\n",
      "- all: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/ALL/v1.0b/profiles_wellpos_cc_var_mad_outlier_featselect_sphering_harmony.parquet\n",
      "- all_interpretable: https://cellpainting-gallery.s3.amazonaws.com/cpg0016-jump-assembled/source_all/workspace/profiles_assembled/ALL/v1.0b/profiles_wellpos_cc_var_mad_outlier_featselect.parquet"
     ]
    }
   ],
   "source": [
    "# Load the JSON manifest\n",
    "response = requests.get(INDEX_FILE)\n",
    "profile_index = response.json()\n",
    "\n",
    "# Display the manifest data\n",
    "for dataset in profile_index:\n",
    "    print(f\"- {dataset['subset']}: {dataset['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b7832-bb9c-49db-b545-9def7a54cfc3",
   "metadata": {},
   "source": [
    "Each profile in the manifest includes direct links to: -\n",
    "**recipe_permalink**: The exact version of the processing code used -\n",
    "**config_permalink**: The specific configuration file that defines the\n",
    "processing steps\n",
    "\n",
    "Letâ€™s display the key information from the manifest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f5b3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert JSON to DataFrame for better display\n",
    "profile_df = pl.DataFrame(profile_index)\n",
    "\n",
    "# Show key information in a clean table\n",
    "display_df = profile_df.select(\n",
    "    [\n",
    "        \"subset\",\n",
    "        pl.col(\"url\").str.extract(r\"([^/]+)\\.parquet$\").alias(\"filename\"),\n",
    "        pl.col(\"recipe_permalink\")\n",
    "        .str.extract(r\"tree/([^/]+)$\")\n",
    "        .str.slice(0, 7)\n",
    "        .alias(\"recipe_version\"),\n",
    "        pl.col(\"config_permalink\").str.extract(r\"([^/]+)\\.json$\").alias(\"config\"),\n",
    "    ]\n",
    ")\n",
    "display_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9707b5-fe8a-421d-80dd-280e75d811ce",
   "metadata": {},
   "source": [
    "Let inspect the standard profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc86296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected profiles:\n",
      "  orf: profiles_wellpos_cc_var_mad_outlier_featselect_sphering_harmony.parquet\n",
      "  crispr: profiles_wellpos_cc_var_mad_outlier_featselect_sphering_harmony_PCA_corrected.parquet\n",
      "  compound: profiles_var_mad_int_featselect_harmony.parquet"
     ]
    }
   ],
   "source": [
    "# Create dictionary of subset -> url for the standard profiles only\n",
    "filepaths = {\n",
    "    dataset[\"subset\"]: dataset[\"url\"]\n",
    "    for dataset in profile_index\n",
    "    if dataset[\"subset\"] in (\"crispr\", \"orf\", \"compound\")\n",
    "}\n",
    "print(\"Selected profiles:\")\n",
    "for subset, url in filepaths.items():\n",
    "    print(f\"  {subset}: {url.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a00a41-c6cf-42de-9503-3336e9eea467",
   "metadata": {},
   "source": [
    "We will lazy-load the dataframes and print the number of rows and\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc56a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = {k: [] for k in (\"dataset\", \"#rows\", \"#cols\", \"#Metadata cols\", \"Size (MB)\")}\n",
    "for name, path in filepaths.items():\n",
    "    data = pl.scan_parquet(path)\n",
    "    n_rows = data.select(pl.len()).collect().item()\n",
    "    schema = data.collect_schema()\n",
    "    metadata_cols = [col for col in schema.keys() if col.startswith(\"Metadata\")]\n",
    "    n_cols = schema.len()\n",
    "    n_meta_cols = len(metadata_cols)\n",
    "    estimated_size = int(round(4.03 * n_rows * n_cols / 1e6, 0))  # B -> MB\n",
    "    for k, v in zip(info.keys(), (name, n_rows, n_cols, n_meta_cols, estimated_size)):\n",
    "        info[k].append(v)\n",
    "\n",
    "pl.DataFrame(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e1ae5-9597-4e48-b680-0147dc092475",
   "metadata": {},
   "source": [
    "Let us now focus on the `crispr` dataset and use a regex to select the\n",
    "metadata columns. We will then sample rows and display the overview.\n",
    "Note that the collect() method enforces loading some data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e76ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pl.scan_parquet(filepaths[\"crispr\"])\n",
    "data.select(pl.col(\"^Metadata.*$\").sample(n=5, seed=1)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918ac8d-2e64-49f2-9779-e51c5c6ee704",
   "metadata": {},
   "source": [
    "The following line excludes the metadata columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cd648a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_only = data.select(pl.all().exclude(\"^Metadata.*$\").sample(n=5, seed=1)).collect()\n",
    "data_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981af5c-9f9b-4258-a591-11d39b40414e",
   "metadata": {},
   "source": [
    "Finally, we can convert this to `pandas` if we want to perform analyses\n",
    "with that tool. Keep in mind that this loads the entire dataframe into\n",
    "memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae87969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p>5 rows Ã— 259 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_only.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "executable": "/usr/bin/env jupyter",
   "text_representation": {
    "extension": ".qmd",
    "format_name": "quarto",
    "format_version": "1.0",
    "jupytext_version": "1.17.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
